ğŸ Cricket Ball Tracking using YOLOv8

This project implements automatic cricket ball detection and tracking from a video using a fine-tuned YOLOv8 model.
The system generates:

ğŸ¥ An annotated output video with ball centroid and trajectory overlaid
ğŸ“„ A CSV file containing per-frame ball coordinates and visibility

ğŸ“ Project Structure

edgefleet_ball_tracking/
â”‚
â”œâ”€â”€ code/                                # Core source code
â”‚   â”œâ”€â”€ inference.py                    # Runs detection + tracking on input video
â”‚   â”œâ”€â”€ tracker.py                      # Ball tracking logic (Kalman / smoothing)
â”‚   â”œâ”€â”€ utils.py                        # Helper utilities
â”‚   â””â”€â”€ train.py                        # YOLO training script 
â”‚
â”œâ”€â”€ data/                                # Raw videos used in project
â”‚   â”œâ”€â”€ train/                          # Training videos
â”‚   â””â”€â”€ test/                           # Test videos for inference
â”‚
â”œâ”€â”€ dataset/                             # YOLO-format dataset (from Roboflow)
â”‚
â”œâ”€â”€ ball_training/                       # YOLO training experiment outputs                  
â”‚
â”œâ”€â”€ models/                              
â”‚   â””â”€â”€ yolov8_ball.pt                  # Final trained ball detection model
â”‚
â”œâ”€â”€ examples/                           # Sample annotated frames showing ball centroid 
â”‚   â””â”€â”€*.png                             # and trajectory overlay    
â”‚
â”œâ”€â”€ annotations/                         # Output CSV files (ball position per frame)
â”‚   â””â”€â”€ *.csv                            
â”‚
â”œâ”€â”€ results/                             
â”‚   â””â”€â”€ *.mp4                           # Processed videos with centroid & trajectory
â”‚
â”œâ”€â”€ README.md                            
â”œâ”€â”€ report.pdf                          
â””â”€â”€ requirements.txt                    


âš™ï¸ Environment Setup
1ï¸âƒ£ Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate   # Windows

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

âš ï¸ Note
If CUDA is not available, install CPU-only PyTorch:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

ğŸ§  Model Details
Architecture: YOLOv8
Framework: Ultralytics
Classes: ball
Input Size: 1280 Ã— 1280
Output: Bounding box â†’ centroid â†’ trajectory

The model is fine-tuned specifically for small object (cricket ball) detection.

â–¶ï¸ Inference
Run inference using:
python code/inference.py --video data/test/9.mov --out_video results/9.mp4 --out_csv annotations/9.csv

ğŸ“¤ Outputs Explained

ğŸ¥ Output Video
Original video with:
ğŸ”´ Red dot â†’ Ball centroid
ğŸ”µ Blue polyline â†’ Ball trajectory (last N frames)

ğŸ“„ Output CSV Format
Column	Description
frame	Frame index (0-based)
x	X-coordinate of ball centroid
y	Y-coordinate of ball centroid
visible	1 if ball detected, else 0

Example:
frame,x,y,visible
0,642,381,1
1,650,389,1
2,-1,-1,0

visible = 0 â†’ Ball not detected in that frame
Coordinates set to -1 when invisible 

ğŸ”„ Tracking Logic
The tracking pipeline works as follows:
YOLO detects the ball in each frame
Highest-confidence detection is selected
Centroid is computed from bounding box
A trajectory buffer (deque) stores recent centroids
Tracker smooths motion and handles brief missed detections
Trajectory is drawn frame-by-frame
If the ball is temporarily missed, the tracker maintains continuity using recent motion history.
When multiple detections are present in a frame, the detection with the highest confidence score is selected as the true ball candidate.

This ensures:
Reduced flickering
Smooth trajectory
Robust tracking across occlusions

ğŸ“¦ Model File
The trained YOLOv8 ball detection model is provided at:
models/yolov8_ball.pt
This model can be directly used for inference without retraining.

ğŸ“„ Detailed Report
A detailed report (`report.pdf`) is included, covering:
- Model training decisions
- Hyperparameter choices
- Tracking logic and fallback handling
- Performance improvements and limitations
- Example qualitative results

ğŸ§ª Tested On
GPU: NVIDIA GeForce MX450 (2GB)
OS: Windows 11
Python: 3.12
CUDA: 12.1

ğŸ‘¤ Author
Himanshu Kumar